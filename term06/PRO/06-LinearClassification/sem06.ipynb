{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297b30e-abdb-4e13-b67a-cdab04d9a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8202f5-dbcb-4a7b-b5de-bee15f3487de",
   "metadata": {},
   "source": [
    "## Решение задачи бинарной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c2d3b-17a1-4079-a2b5-3c4fb66b00db",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "\n",
    "y = {-1, 1}\n",
    "\n",
    "$b(x) = \\sigma(<w,x>)$, где $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "Поработаем с уже известным нам датасетом Titanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d43812-1652-4eec-aab2-8d8470e1e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d1893-6b01-4222-9cb8-97e2000a96bf",
   "metadata": {},
   "source": [
    "Почистим его и оставим только интересующие нас колонки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcea56f-533a-4202-8d48-70430d20ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dcb754-94a3-4cf0-8911-17df9309c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived', axis=1)\n",
    "y = data.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b2368-0142-45ca-9867-83418827af90",
   "metadata": {},
   "source": [
    "Посмотрим, сбалансированная ли у нас выборка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03fba4-1f74-4cda-bd28-da5b0b64e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f7903-78bf-432d-855f-127bb2c1e651",
   "metadata": {},
   "source": [
    "Баланс не очень. Попробуем посмотреть сразу все скоры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06992c-2647-4ae6-8255-070d2237d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "ypred_train = model.predict(X_train)\n",
    "ypred_test = model.predict(X_test)\n",
    "print(classification_report(ypred_train, y_train), classification_report(ypred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5fcca-2aa3-4a41-8662-173422c499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "ypred_train = model.predict(X_train)\n",
    "ypred_test = model.predict(X_test)\n",
    "print(classification_report(ypred_train, y_train), classification_report(ypred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe05978-ff57-471d-87fa-74b4e0785f6a",
   "metadata": {},
   "source": [
    "Как видим, мало отличается от работы с регрессией, синтаксис все тот же. Как sklearn понимает вообще, что у нас данные для регрессии или для классификации? А никак, мы можем спокойно применять регрессию к данным, предназначенным для классификации, и наоборот, решаем только мы сами, какой алгоритм куда больше подходит. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286d749-4a02-40e1-86e9-fffe598ca77a",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Поработаем с датасетом про кредиты: нам нужно решить, давать кредит человеку или нет. Попробуем отмасштабировать данные и заодно собрать все в пайплайн, чтобы было удобнее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e0230-a4f4-41e5-8444-fb6e2f1729b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('loan_sanction_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a16ebe9-78e3-4a19-ad11-e6e38431c8e2",
   "metadata": {},
   "source": [
    "Поработаем с признаками и дропнем пропуски. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7342c41-02a5-4405-9152-8740fe1fd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac858e-cfe4-4783-9f20-6f24f6899fe1",
   "metadata": {},
   "source": [
    "Разделим на трейн и тест. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56657412-7cde-4f3a-832f-eafc50aa24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Loan_Status', axis=1)\n",
    "y = data.Loan_Status\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ad126-c676-4dd5-9ad0-e4774d055a46",
   "metadata": {},
   "source": [
    "Соберем пайплайн: комбайн, который будет внутри себя сразу гонять и масштабирование, и модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe2c92-4efc-46d1-a32f-f2fb521c31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331b173-baa3-48fd-849e-dc73c68c1dd2",
   "metadata": {},
   "source": [
    "Альтернативный вариант:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eda0ab-a10f-4f4c-8693-366da5b3fec1",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a507e-b8ee-4a0d-a5bd-7a03bb2929dc",
   "metadata": {},
   "source": [
    "В чем между ними разница? Во-первых, второе - упрощенный синтаксис, вы не прописываете вручную ярлычки для своих шагов пайплайна. Во-вторых, получается, эти ярлычки приписываются автоматически (по правилу: название класса строчными буквами, например, у StandardScaler автоматически будет ярлычок standardscaler). Это сакральное знание пригодится, когда будем гридсерчить параметры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0bfda-65e2-45a8-a8e6-375ad1958b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "ypred_train = pipe.predict(X_train)\n",
    "ypred_test = pipe.predict(X_test)\n",
    "print(classification_report(ypred_train, y_train), classification_report(ypred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03129d5-04ad-467d-a101-b6e17d973df8",
   "metadata": {},
   "source": [
    "### Несбалансированные классы\n",
    "\n",
    "Давайте порешаем еще одну финансовую задачку: будем предсказывать, возьмет клиент банка кредит или нет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06659d-936c-4cc2-aad8-a9c5b60cfd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0b702-7247-401a-bcce-cd72e75b554e",
   "metadata": {},
   "source": [
    "Для начала просто дропнем все нечисловые характеристики. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e15fa6-846e-435d-9ff2-bb0f96d4257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.select_dtypes(include=np.number)\n",
    "y = data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f001a-795c-4d6c-9517-33946febfd9e",
   "metadata": {},
   "source": [
    "Проверим распределение классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4622eec-4304-4341-af7b-df92c954849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d813f-bb19-4f0c-9b79-f735ffcd4f60",
   "metadata": {},
   "source": [
    "Обучите обычную логистическую регрессию на этом датасете и выведите classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfc3f8-b7ea-46a2-aa7d-49321cb0bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y) # параметр stratify делает подвыборки с равномерным (по возможности) распределением классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5789e-f5e1-4e0d-a7cb-130de09908ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f70acb-2de5-4e64-9930-f94ef3747b15",
   "metadata": {},
   "source": [
    "Какие выводы можете сделать на основании метрик?\n",
    "\n",
    "А теперь давайте применим особую магию с class_weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a523e3-d12f-450d-a537-f4e642e99308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
