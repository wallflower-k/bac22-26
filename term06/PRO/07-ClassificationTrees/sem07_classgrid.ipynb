{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f922529-47d6-44a9-9a12-c149908f356f",
   "metadata": {},
   "source": [
    "# Задача 1. \n",
    "\n",
    "Давайте решим задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k. Каждый объект выборки — человек, для которого известны следующие признаки:\n",
    " - age\n",
    " - workclass\n",
    " - fnlwgt\n",
    " - education\n",
    " - education-num\n",
    " - marital-status\n",
    " - occupation\n",
    " - relationship\n",
    " - race\n",
    " - sex\n",
    " - capital-gain\n",
    " - capital-loss\n",
    " - hours-per-week\n",
    " \n",
    "Более подробно про признаки можно почитать [здесь](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). Целевой признак записан в переменной *>50K,<=50K*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9a3ca-2aa1-41b9-aa74-44b1901f2dd9",
   "metadata": {},
   "source": [
    "Оценивать качество мы будем с помощью ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be106038-1f7d-4fd3-a5be-4fb32b73adee",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров модели\n",
    "\n",
    "В задачах машинного обучения следует различать параметры модели и гиперпараметры (структурные параметры). Обычно параметры модели настраиваются в ходе обучения (например, веса в линейной модели или структура решающего дерева), в то время как гиперпараметры задаются заранее (например, регуляризация в линейной модели или максимальная глубина решающего дерева). Каждая модель обычно имеет множество гиперпараметров, и нет универсальных наборов гиперпараметров, оптимально работающих во всех задачах, для каждой задачи нужно подбирать свой набор.\n",
    "\n",
    "Для оптимизации гиперпараметров модели часто используют _перебор по сетке (grid search)_: для каждого гиперпараметра выбирается несколько значений, перебираются все комбинации значений и выбирается комбинация, на которой модель показывает лучшее качество (с точки зрения метрики, которая оптимизируется). Однако в этом случае нужно грамотно оценивать построенную модель, а именно делать разбиение на обучающую и тестовую выборку. Есть несколько схем, как это можно реализовать: \n",
    "\n",
    " - Разбить имеющуюся выборку на обучающую и тестовую. В этом случае сравнение большого числа моделей при переборе параметров приводит к ситуации, когда лучшая на тестовой подвыборке модель не сохраняет свои качества на новых данных. Можно сказать, что происходит _переобучение_ на тестовую выборку.\n",
    " - Для устранения описанной выше проблемы, можно разбить данные на 3 непересекающихся подвыборки: обучение (`train`), валидация (`validation`) и контроль (`test`). Валидационную подвыборку используют для сравнения моделей, а `test` — для окончательной оценки качества и сравнения семейств моделей с подобранными параметрами.\n",
    " - Другой способ сравнения моделей — [кросс-валидация](http://en.wikipedia.org/wiki/Cross-validation_(statistics). Существуют различные схемы кросс-валидации:\n",
    "  - Leave-One-Out\n",
    "  - K-Fold\n",
    "  - Многократное случайное разбиение выборки\n",
    "  \n",
    "Кросс-валидация вычислительно затратна, особенно если вы делаете перебор по сетке с очень большим числом комбинации. С учетом конечности времени на выполнение задания, возникает ряд компромиссов: \n",
    "  - сетку можно делать более разреженной, перебирая меньше значений каждого параметра; однако, надо не забывать, что в таком случае можно пропустить хорошую комбинацию параметров;\n",
    "  - кросс-валидацию можно делать с меньшим числом разбиений или фолдов, но в таком случае оценка качества кросс-валидации становится более шумной и увеличивается риск выбрать неоптимальный набор параметров из-за случайности разбиения;\n",
    "  - параметры можно оптимизировать последовательно (жадно) — один за другим, а не перебирать все комбинации; такая стратегия не всегда приводит к оптимальному набору;\n",
    "  - перебирать не все комбинации параметров, а небольшое число случайно выбранных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0066f1-3c76-46f4-bd5d-fa15e210b4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3cc517-453e-4bb9-bfcd-3309bcad3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.adult.csv')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c315ea7-4398-4c51-84f2-d6a5cbb14618",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes  # понадобится потом, чтобы отделить нечисловые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb23e5-1b11-45a7-a63d-9f86ea7db1e9",
   "metadata": {},
   "source": [
    "Иногда в данных встречаются пропуски. Как задаются пропуски обычно либо прописывается в описании к данным, либо просто на месте пропуска после чтения данных оказывается значение numpy.nan. Более подробно о работе с пропусками в Pandas можно прочитать например [здесь](http://pandas.pydata.org/pandas-docs/stable/missing_data.html). \n",
    "\n",
    "В данном датасете пропущенные значения обозначены как \"?\". \n",
    "\n",
    "Найдем все признаки, имеющие пропущенные значения. Удалим из выборки все объекты с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac1463-2ac6-4aa8-ad39-dbc548577ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isin(['?']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e832f3a-9a1b-4563-be3f-5ac307272e17",
   "metadata": {},
   "source": [
    "workclass & occupation содержат пропущенные значения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd229ae5-fa79-454d-bf4b-7f14332962a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.workclass != '?') & (data.occupation != '?')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19e548-eca7-404f-a500-66a37a5de688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.isin(['?']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8946dba0-d444-46e2-8cda-abe122d76bef",
   "metadata": {},
   "source": [
    "Обычно после загрузки датасета всегда необходима его некоторая предобработка. В данном случае она будет заключаться в следующем: \n",
    "\n",
    " - Выделим целевую переменную в отдельную переменную, удалим ее из датасета и преобразуем к бинарному формату.\n",
    " - Не все признаки являются вещественными. В начале мы будем работать только с вещественными признаками. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca93b8-5796-42c4-af90-eb588f9dc95b",
   "metadata": {},
   "source": [
    "Преобразовываем в бинарный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14706452-2323-456a-8c42-64ca87857dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['>50K,<=50K'] = data['>50K,<=50K'].apply(lambda x: 1 if x == '>50K' else -1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30aacc-8e19-4c35-9679-0d39b67f4dea",
   "metadata": {},
   "source": [
    "Выделим целевую переменную в y, числовые признаки - в Х"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44573f36-bdf3-45f6-8d84-ec6027fbda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['>50K,<=50K']\n",
    "X = data[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa1fab-debe-4baf-a9d5-66ebc3428704",
   "metadata": {},
   "source": [
    "Разобьем Х на тест и трейн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee87e1-cb03-45b4-9546-136ca8cdc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94f6da-3da1-4a43-b10f-195cb33b55af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Обучение классификаторов на вещественных признаках\n",
    "\n",
    "В данном разделе необходимо будет работать только с вещественными признаками и целевой переменной.\n",
    "\n",
    "В начале посмотрим как работает подбор параметров по сетке и как влияет на качество разбиение выборки. Сейчас и далее будем рассматривать 5 алгоритмов:\n",
    " - kNN\n",
    " - SGD Linear Classifier (SVС со стохастическим градиентным спуском)\n",
    " - Naive Bayes Classifier\n",
    " - Logistic Regression\n",
    " - SVC (Support Vector Classifier)\n",
    " \n",
    "Для начала у первых двух алгоритмов выберем один гиперпараметр, который будем оптимизировать:\n",
    " - kNN — число соседей (*n_neighbors*)\n",
    " - SGD Linear Classifier — оптимизируемая функция (*loss*)\n",
    " \n",
    "Остальные параметры будем оставлять в значениях по умолчанию. Для подбора гиперпараметров воспользуемся перебором по сетке, который реализован в классе GridSearchCV. В качестве схемы кросс-валидации будем использовать 5-fold cv.\n",
    "\n",
    "Для каждого из первых двух алгоритмов подберем оптимальные значения указанных гиперпараметров. Построим график среднего качества по кросс-валидации алгоритма при заданном значении гиперпараметра, на котором также отобразим доверительный интервал (доверительный интервал задается границами [mean - std, mean + std])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585cc66-d2d8-48c6-8a72-ff9fb1da1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(grid, params):\n",
    "    \"\"\"Функция для построения графиков\"\"\"\n",
    "    scores_mean = grid.cv_results_['mean_test_score']\n",
    "    scores_sd = grid.cv_results_['std_test_score']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(params,scores_mean)\n",
    "    ax.fill_between(params, (scores_mean-scores_sd), (scores_mean+scores_sd), color='g', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706aa2cb-9a07-403b-8bb5-b9b4ea3e7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, param_grid, hyperparams):\n",
    "    \"\"\"Функция подбора гиперпараметров, вызывает функцию с графиками\"\"\"\n",
    "    grid = GridSearchCV(model, param_grid, scoring='roc_auc')  # если не передавать cv явно, как раз будет использована 5-fold cv\n",
    "    grid.fit(Xtrain, ytrain)\n",
    "    plotting(grid, hyperparams)\n",
    "    print(f'Best params: {grid.best_params_}')\n",
    "    best = grid.best_estimator_\n",
    "    y_pred_train = best.predict(Xtrain)\n",
    "    y_pred_test = best.predict(Xtest)\n",
    "    print(classification_report(ytrain, y_pred_train), classification_report(ytest, y_pred_test))\n",
    "    print(roc_auc_score(ytrain, y_pred_train), roc_auc_score(ytest, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fece6fe-43cc-4195-b43e-54eb8c2d1780",
   "metadata": {},
   "source": [
    "**KNN Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f37bd6-d8a4-4352-bc1c-1ae5caff4cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "hyperparams = list(range(2, 30)) # k=2 до k=30\n",
    "param_grid = {'n_neighbors': hyperparams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f5045-b75d-41a6-9d08-0eee8221f3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('KNN results')\n",
    "model_train(model, param_grid, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1d176-59ed-483d-82fb-1590df2025f0",
   "metadata": {},
   "source": [
    "Попробуем нормализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9879a98-ea01-4225-8f87-dd70a04aa486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "# make_pipeline(...)\n",
    "'kneighborsclassifier__n_neighbors'\n",
    "hyperparams = list(range(2, 30))\n",
    "param_grid = {'knn__n_neighbors': hyperparams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc412ff-1bcb-46a9-bbab-acdf5f2e51f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Normalised KNN results')\n",
    "model_train(model, param_grid, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10fc6a-fa84-4578-97a2-04fa9df0d1c0",
   "metadata": {},
   "source": [
    "**SGDClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba8a71-9a8d-4351-95e3-1054f00e035a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier()\n",
    "hyperparams = ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "param_grid = {'loss': hyperparams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e8043-7117-4976-bf0c-9456c0678f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('SGD results')\n",
    "model_train(model, param_grid, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c468b4-737d-4c9e-9992-489045095fdf",
   "metadata": {},
   "source": [
    "Попробуем нормализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d07a2-aa21-4df8-9c8b-b1121a9638e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('sgd', SGDClassifier())\n",
    "])\n",
    "hyperparams = ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "param_grid = {'sgd__loss': hyperparams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f5118-f103-49ee-935d-58dd15aa27ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Normalised SGD results')\n",
    "model_train(model, param_grid, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168ce6f-8cd3-438d-8f41-3e71a17731ac",
   "metadata": {},
   "source": [
    "hinge - это SVM, log - логистическая регрессия, modified_huber - сглаженный SVM, squared_hinge - SVM, который штрафуется квадратично, perceptron - алгоритм перцептрона (Розенблатт). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa98bf-b2a7-4ae7-b442-d3474b96a887",
   "metadata": {},
   "source": [
    "Гиперпараметры для остальных алгоритмов попробуйте подобрать сами. Нам осталось посмотреть:\n",
    "\n",
    "- LogisticRegression\n",
    "- SVC\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf98bb-849e-4aff-a005-3a3f0ad78269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61fe55-b2a6-4cb4-8d57-0ad49588b054",
   "metadata": {},
   "source": [
    "Также можете попробовать поработать с категориальными признаками. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77009692-a37a-4c59-91d2-b5e41db28c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a7487-4ed6-45f3-80c5-b5c9613e6040",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Смешивание моделей\n",
    "\n",
    "Во всех предыдущих пунктах мы получили много хороших моделей, которые могут быть достаточно разными по своей природе (например, метод ближайших соседей и логистическая регрессия). Часто на практике оказывается возможным увеличить качество предсказания путем смешивания подобных разных моделей. Давайте посмотрим, действительно ли это дает прирост в качестве.\n",
    "\n",
    "Выберем из построенных моделей двух предыдущих пунктов две (обозначим их $clf_1$ и $clf_2$). Далее построим новый классификатор, ответ которого на некотором объекте $x$ будет выглядеть следующим образом:\n",
    "\n",
    "$$result(x) = clf_1(x) \\cdot \\alpha + clf_2(x) \\cdot (1 - \\alpha)$$\n",
    "\n",
    "где $\\alpha$ — гиперпараметр нового классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370cd11-e20b-4ef9-a6ba-1b043ae44193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=29))\n",
    "])\n",
    "model2 = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('sgd', SGDClassifier(loss='log_loss'))\n",
    "])\n",
    "model1.fit(Xtrain, ytrain)\n",
    "model2.fit(Xtrain, ytrain)\n",
    "clf1 = model1.predict_proba(Xtest)\n",
    "clf2 = model2.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61336f-0033-4170-91b7-abd8382db8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for alpha in np.arange(0.1, 1.1, 0.1):\n",
    "    res = alpha * clf1 + (1 - alpha) * clf2\n",
    "\n",
    "    pred = []\n",
    "    for elem in res:\n",
    "        pred.append(np.argmax(elem))\n",
    "    scores.append(roc_auc_score(pred, ytest))\n",
    "    \n",
    "    print('alpha:', round(alpha, 1), 'score:', scores[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3e6e6-9017-4795-a4e5-ffab7939bbde",
   "metadata": {},
   "source": [
    "# Задача 2.\n",
    "\n",
    "Решим задачу распознавания лиц с помощью метода опорных векторов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583a947-4890-4d22-b370-2c6fe0ffc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4d0d4-7870-42e0-8f8d-6e0f94b551d7",
   "metadata": {},
   "source": [
    "Нарисуем несколько лиц из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65896a-ee0d-4886-ba28-b2f869fff837",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(9,9))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43611cff-f0fb-434a-a52a-8af1f7d80fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a470f415-5c2a-49d9-bd36-f4fd9cf6f155",
   "metadata": {},
   "source": [
    "Каждое изображение имеет размер [62×47] - это примерно 3000 пикселей. Мы можем использовать пиксели как признаки, но давайте понизим размерность пространства признаков.\n",
    "\n",
    "Извлечем 150 самых информативных признаков из данных фотографий методом RandomizedPCA (помним, что это метод уменьшения размерности)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44d5bc-0737-4d4e-b7ce-d8a302845a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA #Principal Components Analysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = PCA(n_components=150, svd_solver='randomized', whiten=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52dfc9-c5ec-4cf0-805f-a33121710757",
   "metadata": {},
   "source": [
    "Попробуем решить задачу алгоритмом SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405ba07-21ff-4393-a177-e81154ce01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "\n",
    "model = make_pipeline(pca, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d8cb6-c917-4ad4-bd47-6aab9449fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82eb769-d8b8-4594-98af-b8d56e512cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C': [1, 5, 10, 50]}\n",
    "grid = GridSearchCV(model, param_grid)\n",
    "\n",
    "%time grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81ec79-c5a6-4c5d-a47d-f9c82fdbaeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "\n",
    "yfit = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60684eff-36f5-4bd0-9155-cc8fe24c164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 6, figsize=(9,9))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
    "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08721f8-f835-48df-9f54-3fb4a4a6a177",
   "metadata": {},
   "source": [
    "Выведем на экран метрики классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fb6bf-c662-4497-8683-3b0d2d3dad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, yfit,\n",
    "                            target_names=faces.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf841d-b4b7-495c-8a97-22adae588767",
   "metadata": {},
   "source": [
    "Нарисуем матрицу ошибок классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fae278-ef6b-44f8-8049-53d063c1b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=faces.target_names,\n",
    "            yticklabels=faces.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70ba1f-a552-4706-a207-dc8064d9097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(yfit,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858e9e3-c6ee-43dc-8978-04db0a0b9157",
   "metadata": {},
   "source": [
    "## Решение нелинейных задач с помощью SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2b22e-114e-425e-b61a-dc2ba91d3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=300, linewidth=1, facecolors='none');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9e309-631e-47a7-9583-ba26da588948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(100, factor=.1, noise=.1)\n",
    "\n",
    "clf = SVC(kernel='linear').fit(X, y)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf, plot_support=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b2a94-a8f5-41b5-a6c5-016290487d2f",
   "metadata": {},
   "source": [
    "Перейдем в пространство новой (большей) размерности. В данном примере в качестве третьей координаты можно использовать радиальную фунцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d2a6a-cd94-48c4-8bb1-2310697e00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.exp(-(X ** 2).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0d1d5-cc80-4a33-bf7b-cc22525879d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "def plot_3D(elev=30, azim=30, X=X, y=y):\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap='autumn')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('r')\n",
    "\n",
    "interact(plot_3D, elev=[-90, -45, 0, 35, 90], azip=(-180, 180),\n",
    "         X=fixed(X), y=fixed(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bb678-efed-421a-9d13-f191d7822911",
   "metadata": {},
   "source": [
    "Видим, что в новом пространстве выборка стала линейно разделимой.\n",
    "\n",
    "Решение исходной задачи в новом пространстве с помощью SVM называется ядровым SVM (Kernel SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d2a31-c4fa-4969-876c-bc397cc7e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', C=1E6) #rbf = radial basis function\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bddd9d-c1f8-468b-a318-9502cb88db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf)\n",
    "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n",
    "            s=300, lw=1, facecolors='none');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
