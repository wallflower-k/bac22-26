{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd60066-19da-4094-9658-b2420b950ee7",
   "metadata": {},
   "source": [
    "### Работа со звуком в питоне"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857db197-2fe3-4f4a-a7a1-d98d17d73f91",
   "metadata": {},
   "source": [
    "#### Автоматическое распознание речи (ASR = automatic speech recognition)\n",
    "\n",
    "ASR - это отдельная большая область компьютерной лингвистики и NLP со своими особенностями. Распознание (и генерация) речи привлекали интерес исследователей еще в шестидесятых годах прошлого века; первые программы для распознания речи появились уже тогда. Сегодня ASR осуществляется почти исключительно с помощью нейронных сетей (генерация, разумеется, тоже). \n",
    "\n",
    "Можно выделить три возможных метода распознания речи:\n",
    "\n",
    "- акустический фонетический подход (1967 год)\n",
    "- распознание паттерна (1993 год)\n",
    "- с использованием ИИ (сегодня)\n",
    "\n",
    "До того, как ИИ стал популярным и достаточно мощным, самый очевидный подход предполагал, что существуют различные фонетические элементы в устной речи, причем каждый такой элемент обладает своими акустическими свойствами. В общем-то, это вроде бы верно, но проблема заключается в том, что у разных носителей эти свойства могут быть очень отличающимися. Соответственно, самые первые программы пытались анализировать спектр речи, вычленять нужные признаки и затем сегментировать речь по фонемам, приписывая каждой фонеме ярлык. \n",
    "\n",
    "Более популярный (и позднее придуманный) метод может быть двух видов: первый вид - это когда мы сравниваем услышанное с набором шаблонов произнесенных слов (template method) и пытаемся угадать, какой больше подходит; второй - с использованием классического машинного обучения (еще называют стохастический, или вероятностный - потому что любое МО основано на вычислении вероятностей). \n",
    "\n",
    "Современный подход с использованием нейронных сетей объединяет оба предыдущих подхода и еще подключает искусственный интеллект. Это уже совсем сложная технически задача, но если вкратце, то такой подход включает в себя следующие шаги:\n",
    "\n",
    "1. Получение звукового сигнала\n",
    "2. Извлечение признаков (нейронные сети самостоятельно умеют извлекать признаки)\n",
    "3. Акустическое моделирование (сеть, грубо говоря, распознает фонемы)\n",
    "4. Языковое и лексическое моделирование (фонемы => слова)\n",
    "\n",
    "Современные модели ASR бывают общие (им неважно, чью речь они распознают) и натренированные на одного пользователя или группу пользователей. Первые - самые сложные (ввиду разницы в произношении разных людей), вторые попроще. Еще бывают модели ASR, которые умеют дообучаться: скорее всего, на вашем телефоне распознает речь именно такая модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03738204-04af-4b7e-87b0-f64d8f51d9a7",
   "metadata": {},
   "source": [
    "#### Базовые библиотеки для работы со звуком"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fbf10-b823-4625-a4fa-57d421c83085",
   "metadata": {},
   "source": [
    "Питон, разумеется, умеет работать со звуком. В первую очередь нужно установить библиотеку pyaudio (она пригодится для разных вещей):\n",
    "\n",
    "    pip install pyaudio\n",
    "    \n",
    "Без проблем эта библиотека устанавливается только на Windows. На макбуке понадобится устанавливать ее дополнительно через homebrew:\n",
    "\n",
    "    brew install portaudio\n",
    "    pip install pyaudio\n",
    "    \n",
    "На линуксе (имейте в виду: колаб = линукс!) необходимо тоже отдельно установить кое-что через apt:\n",
    "\n",
    "    apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
    "    pip install pyaudio\n",
    "    \n",
    "В колабе обе эти команды можно выполнить с восклицательным знаком в обычной ячейке (apt работает так же, как pip). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccaca7-5a33-44d7-831c-bca14b28b921",
   "metadata": {},
   "source": [
    "Воспроизводить звук можно с помощью библиотеки playsound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "212b715b-50de-4607-95a1-613fc9d1f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\sukho\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "    Error 263 for command:\n",
      "        open Ellipsis\n",
      "    Указанное устройство не открыто или не опознается интерфейсом MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close Ellipsis\n",
      "    Указанное устройство не открыто или не опознается интерфейсом MCI.\n",
      "Failed to close the file: Ellipsis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7044 sha256=9d2c80a600ac7501323ce61412ccef5d7d69a71d654cb4906209b052e3dce5ed\n",
      "  Stored in directory: c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\50\\98\\42\\62753a9e1fb97579a0ce2f84f7db4c21c09d03bb2091e6cef4\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    },
    {
     "ename": "PlaysoundException",
     "evalue": "\n    Error 263 for command:\n        open Ellipsis\n    Указанное устройство не открыто или не опознается интерфейсом MCI.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPlaysoundException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaysound\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m playsound\n\u001b[0;32m      5\u001b[0m fullpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m \u001b[38;5;66;03m# важно: playsound не может проиграть файл по относительному пути\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplaysound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\playsound.py:72\u001b[0m, in \u001b[0;36m_playsoundWin\u001b[1;34m(sound, block)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m     \u001b[43mwinCommand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msound\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     winCommand(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplay \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sound, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m wait\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     74\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturning\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\playsound.py:64\u001b[0m, in \u001b[0;36m_playsoundWin.<locals>.winCommand\u001b[1;34m(*command)\u001b[0m\n\u001b[0;32m     60\u001b[0m     exceptionMessage \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    Error \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(errorCode) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for command:\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     61\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m command\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     62\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m errorBuffer\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\0\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     63\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(exceptionMessage)\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PlaysoundException(exceptionMessage)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[1;31mPlaysoundException\u001b[0m: \n    Error 263 for command:\n        open Ellipsis\n    Указанное устройство не открыто или не опознается интерфейсом MCI."
     ]
    }
   ],
   "source": [
    "!pip install playsound\n",
    "\n",
    "from playsound import playsound\n",
    "\n",
    "fullpath = ... # важно: playsound не может проиграть файл по относительному пути\n",
    "playsound(fullpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406480f-8168-4db1-b1eb-c97b2339d281",
   "metadata": {},
   "source": [
    "Можно конвертировать звуковые файлы из одного формата в другой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44779e3d-bc3b-4dae-972e-afccfc78afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# пути для конвертации                                                                         \n",
    "src = \"audio.mp3\"\n",
    "dst = \"audio.wav\"\n",
    "\n",
    "# mp3 => wav                                                           \n",
    "sound = AudioSegment.from_mp3(src)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4273dd-9220-41fc-b857-b1db2bdae1d4",
   "metadata": {},
   "source": [
    "Другие примеры использования библиотеки pydub можно найти на ее [странице гитхаба](https://github.com/jiaaro/pydub). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefaa6d-15a4-48fc-9ba5-e51b11246316",
   "metadata": {},
   "source": [
    "#### Генерация и распознание речи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99414690-f394-49fa-9b69-b3c044a03fd3",
   "metadata": {},
   "source": [
    "Существует довольно большое количество готовых моделей генерации речи и ее распознания; мы с вами нейронные сети обучать, конечно, не будем, воспользуемся готовыми инструментами. Для генерации речи можно легко использовать Google Text-to-Speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce40b1bd-6c2d-4f02-887f-73a192e81ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\sukho\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gtts) (8.1.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sukho\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts\n",
    "\n",
    "from gtts import gTTS\n",
    "\n",
    "tts = gTTS('текст', lang='ru')\n",
    "tts.save('audio.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe48ded-8d6f-4d55-a7ad-498ba3ba55ab",
   "metadata": {},
   "source": [
    "gTTS поддерживает большое количество разных языков (и их вариантов), полный список можно посмотреть [тут](https://cloud.google.com/text-to-speech/docs/voices). Можно указать только первые две буквы (например, en), а можно уточнить, какую версию хочется, например, en-US - для американского варианта произношения. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b710b-0351-4ea6-ba1a-caa33fdd9361",
   "metadata": {},
   "source": [
    "Для распознания речи существует библиотека SpeechRecognition, которая умеет работать с несколькими разными моделями. \n",
    "\n",
    "    pip install SpeechRecognition\n",
    "\n",
    "Также может понадобиться установить дополнительные библиотеки типа Vosk или pocketsphinx (это тоже модели распознания речи). \n",
    "\n",
    "В колабе микрофон, к сожалению, использовать не получится (но в Windows из локальной среды разработки - запросто!), поэтому остается только складывать в колаб готовые записи для распознания. \n",
    "\n",
    "Так можно распознать готовый аудиофайл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db617b9f-cdd8-48b4-8de8-bd427e2a21a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n\u001b[0;32m      3\u001b[0m AUDIO_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# путь к файлу-источнику\u001b[39;00m\n\u001b[0;32m      5\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "AUDIO_FILE = \"audio.wav\" # путь к файлу-источнику\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source)  # читает файл в свой внутренний формат\n",
    "\n",
    "try:\n",
    "    print(r.recognize_google(audio, language='en')) \n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition не справился\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Ошибка запроса: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad16fd-ea5f-48e6-bfee-c3887c4336b8",
   "metadata": {},
   "source": [
    "Speech Recognition поддерживает только wav, aiff и flac расширения (но мы можем конвертировать mp3 в wav...)\n",
    "\n",
    "Если вы работаете локально с компьютера, на котором есть микрофон, можно заставить SR распознавать речь прямо с микрофона:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36970fb2-e5e8-4eb8-8899-e9246e89921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Я вас слушаю!\")\n",
    "    audio = r.listen(source, 5, 15) # ждать 5 сек, слушать 15 сек\n",
    "    \n",
    "# в audio окажется записанный (но не сохраненный) звук с микрофона\n",
    "    \n",
    "try:\n",
    "    print(r.recognize_google(audio, language='ru')) \n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition не справился\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Ошибка запроса: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64cc7e-fb61-493d-856f-a1a079d5afc7",
   "metadata": {},
   "source": [
    "SR может и просто записывать файлы с микрофона (после того, как послушал):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b220e-40cd-4e2f-bfa9-60c7171def98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write audio to a RAW file\n",
    "with open(\"microphone-results.raw\", \"wb\") as f:\n",
    "    f.write(audio.get_raw_data())\n",
    "\n",
    "# write audio to a WAV file\n",
    "with open(\"microphone-results.wav\", \"wb\") as f:\n",
    "    f.write(audio.get_wav_data())\n",
    "\n",
    "# write audio to an AIFF file\n",
    "with open(\"microphone-results.aiff\", \"wb\") as f:\n",
    "    f.write(audio.get_aiff_data())\n",
    "\n",
    "# write audio to a FLAC file\n",
    "with open(\"microphone-results.flac\", \"wb\") as f:\n",
    "    f.write(audio.get_flac_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253c32f-eebc-4765-9752-315d10739fd2",
   "metadata": {},
   "source": [
    "А вот и (примерный) список поддерживаемых языков:\n",
    "\n",
    "    + Afrikaans af\n",
    "    + Basque eu\n",
    "    + Bulgarian bg\n",
    "    + Catalan ca\n",
    "    + Arabic (Egypt) ar-EG\n",
    "    +? Arabic (Jordan) ar-JO\n",
    "    + Arabic (Kuwait) ar-KW\n",
    "    +? Arabic (Lebanon) ar-LB\n",
    "    + Arabic (Qatar) ar-QA\n",
    "    + Arabic (UAE) ar-AE\n",
    "    .+ Arabic (Morocco) ar-MA\n",
    "    .+ Arabic (Iraq) ar-IQ\n",
    "    .+ Arabic (Algeria) ar-DZ\n",
    "    .+ Arabic (Bahrain) ar-BH\n",
    "    .+ Arabic (Lybia) ar-LY\n",
    "    .+ Arabic (Oman) ar-OM\n",
    "    .+ Arabic (Saudi Arabia) ar-SA\n",
    "    .+ Arabic (Tunisia) ar-TN\n",
    "    .+ Arabic (Yemen) ar-YE\n",
    "    + Czech cs\n",
    "    + Dutch nl-NL\n",
    "    + English (Australia) en-AU\n",
    "    +? English (Canada) en-CA\n",
    "    + English (India) en-IN\n",
    "    + English (New Zealand) en-NZ\n",
    "    + English (South Africa) en-ZA\n",
    "    + English(UK) en-GB\n",
    "    + English(US) en-US\n",
    "    + Finnish fi\n",
    "    + French fr-FR\n",
    "    + Galician gl\n",
    "    + German de-DE\n",
    "    + Hebrew he\n",
    "    + Hungarian hu\n",
    "    + Icelandic is\n",
    "    + Italian it-IT\n",
    "    + Indonesian id\n",
    "    + Japanese ja\n",
    "    + Korean ko\n",
    "    + Latin la\n",
    "    + Mandarin Chinese zh-CN\n",
    "    + Traditional Taiwan zh-TW\n",
    "    +? Simplified China zh-CN ?\n",
    "    + Simplified Hong Kong zh-HK\n",
    "    + Yue Chinese (Traditional Hong Kong) zh-yue\n",
    "    + Malaysian ms-MY\n",
    "    + Norwegian no-NO\n",
    "    + Polish pl\n",
    "    +? Pig Latin xx-piglatin\n",
    "    + Portuguese pt-PT\n",
    "    .+ Portuguese (brasil) pt-BR\n",
    "    + Romanian ro-RO\n",
    "    + Russian ru\n",
    "    + Serbian sr-SP\n",
    "    + Slovak sk\n",
    "    + Spanish (Argentina) es-AR\n",
    "    + Spanish(Bolivia) es-BO\n",
    "    +? Spanish( Chile) es-CL\n",
    "    +? Spanish (Colombia) es-CO\n",
    "    +? Spanish(Costa Rica) es-CR\n",
    "    + Spanish(Dominican Republic) es-DO\n",
    "    + Spanish(Ecuador) es-EC\n",
    "    + Spanish(El Salvador) es-SV\n",
    "    + Spanish(Guatemala) es-GT\n",
    "    + Spanish(Honduras) es-HN\n",
    "    + Spanish(Mexico) es-MX\n",
    "    + Spanish(Nicaragua) es-NI\n",
    "    + Spanish(Panama) es-PA\n",
    "    + Spanish(Paraguay) es-PY\n",
    "    + Spanish(Peru) es-PE\n",
    "    + Spanish(Puerto Rico) es-PR\n",
    "    + Spanish(Spain) es-ES\n",
    "    + Spanish(US) es-US\n",
    "    + Spanish(Uruguay) es-UY\n",
    "    + Spanish(Venezuela) es-VE\n",
    "    + Swedish sv-SE\n",
    "    + Turkish tr\n",
    "    + Zulu zu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d28331-ef2e-461d-9abb-72a643b85723",
   "metadata": {},
   "source": [
    "#### Работа с разметкой Praat, ELAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807e301-f5d7-49a5-b098-1ff2d46f2864",
   "metadata": {},
   "source": [
    "Существует несколько таких библиотек, мы возьмем на вооружение две:\n",
    "\n",
    "    pip install pympi-ling\n",
    "    pip install praat-textgrids\n",
    "    \n",
    "Как можно работать с разметкой ELAN (.eaf - файлы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea24f2e-1155-44f7-ad63-277eaedbe25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympi import Elan\n",
    "\n",
    "doc = Elan.Eaf(file_path='...') # открываем файл\n",
    "\n",
    "# у нашей разметки есть некоторые атрибуты:\n",
    "doc.tiers # уровни\n",
    "doc.linguistic_types \n",
    "doc.languages\n",
    "doc.timeslots\n",
    "\n",
    "# Можно вручную добавлять аннотацию:\n",
    "doc.add_annotation('имя уровня', start, end, value='что вписать')\n",
    "\n",
    "doc.add_language(lang_id) # добавить язык\n",
    "doc.add_linguistic_type(lingtype) # добавить лингвистический тип\n",
    "\n",
    "doc.add_tier(ID, ling) # добавить уровень разметки\n",
    "\n",
    "doc.extract(start, end) # нарезать файл: удалит указанный интервал и вернет копию файла без него\n",
    "\n",
    "doc.filter_annotations(tier, filtin=['строки, которые нужно показывать'], filtex=['ненужные строки'], regex=True)\n",
    "\n",
    "doc.get_annotation_data_for_tier(ID) # вывести все, что аннотировано на уровне\n",
    "\n",
    "doc.get_annotation_data_after_time(...)\n",
    "doc.get_annotation_data_at_time(...)\n",
    "doc.get_annotation_data_before_time(...)\n",
    "doc.get_annotation_data_between_times(...)\n",
    "\n",
    "doc.get_full_time_interval() # вернет интервал - начало и конец времени разметки в файле\n",
    "doc.get_gaps_and_overlaps(tier1, tier2, maxlen=-1) # возвращает генератор; вычисляет паузы и оверлапы, если в размеченном файле болььше одного говорящего\n",
    "# по методу в Heldner, M., & Edlund, J. (2010). Pauses, gaps and overlaps in conversations. Journal of Phonetics, 38(4), 555–568.\n",
    "\n",
    "# Слить два уровня в один  новый\n",
    "doc.merge_tiers(tiers, tiernew=None, gapt=0, sep='_', safe=False)\n",
    "\n",
    "doc.remove_all_annotations_from_tier(id_tier, clean=True) # удалить разметку с уровня\n",
    "\n",
    "doc.remove_annotation(id_tier, time, clean=True)\n",
    "\n",
    "doc.remove_tier(id_tier, clean=True)\n",
    "\n",
    "doc.rename_tier(id_from, id_to)\n",
    "\n",
    "doc.shift_annotations(time) # сместить разметку по времени\n",
    "\n",
    "doc.to_file(file_path, pretty=True) # сохранить файл\n",
    "\n",
    "doc.to_textgrid(filtin=[], filtex=[], regex=False) # конвертировать в textgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b67d7-cdb7-4d3e-807c-d73fb64a1308",
   "metadata": {},
   "source": [
    "Как можно работать с разметкой Praat (textgrid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730ab79-0974-44fb-aa6c-66aa1cd8db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrids\n",
    "\n",
    "grid = textgrids.TextGrid(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb20b9-857a-44bc-87ed-3d88146cf5be",
   "metadata": {},
   "source": [
    "Объект grid - это словарь, в котором ключами являются имена уровней, а значениями - сами уровни (tiers) разметки. Уровень разметки - это специальный список, который может хранить в себе интервалы praat или points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f4671b3-efe2-4671-b59d-aada3f33f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Interval text=\"pC-001\" xmin=0.0 xmax=219.74375>,\n",
       " <Interval text=\"C-vN001\" xmin=219.74375 xmax=219.91762>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid['C-lines'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa9ce7-cf37-49c2-96e4-468beae751a1",
   "metadata": {},
   "source": [
    "Например, уровень C-lines хранит в себе интервалы, где записан текст, относящийся к ним, и время начала и конца интервала. \n",
    "\n",
    "Интервал - это тоже специальный объект, у которого есть такие методы:\n",
    "\n",
    "    containsvowel\n",
    "    dur\n",
    "    endswithvowel\n",
    "    mid\n",
    "    offset_time\n",
    "    startswithvowel\n",
    "    text\n",
    "    timegrid\n",
    "    xmax\n",
    "    xmin\n",
    "    \n",
    "Что означает большинство из них, должно быть понятно по названию. Также у интервала есть такие атрибуты:\n",
    "\n",
    "    text\n",
    "    xmin\n",
    "    xmax\n",
    "    \n",
    "В атрибуте text хранится специальный объект Transcript, у которого есть метод transcode, который переводит текст из Praat в юникод или наоборот. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b0a53-173a-4d12-ae86-ed0d8b6728a8",
   "metadata": {},
   "source": [
    "Наконец, в модуле есть набор переменных, которые хранят в себе полезные вещи:\n",
    "\n",
    "diacritics - список (словарь) всех диакритик с их эквивалентами в юникоде\n",
    "inline_diacritics - словарь символьных диакритик\n",
    "index_diacritics - словарь диакритик для подчеркивания\n",
    "symbols - список специальных символов Praat с их юникод-вариантами\n",
    "vowels - список гласных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb97bf0-b4ff-45ca-85da-1263a320869d",
   "metadata": {},
   "source": [
    "Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3696b97-2da0-42a1-a64d-1b829da495ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'e', 'i', 'o', 'u', 'y', 'æ', 'ø', '\\\\i-', '\\\\u-', '\\\\mt', '\\\\ic', '\\\\yc', '\\\\hs', '\\\\o/', '\\\\e-', '\\\\o-', '\\\\rh', '\\\\sw', '\\\\ef', '\\\\oe', '\\\\er', '\\\\kb', '\\\\vt', '\\\\ct', '\\\\ae', '\\\\at', '\\\\Oe', '\\\\as', '\\\\ab', 'ɨ', 'ʉ', 'ɯ', 'ɪ', 'ʏ', 'ʊ', 'ø', 'ɘ', 'ɵ', 'ɤ', 'ə', 'ɛ', 'œ', 'ɜ', 'ɞ', 'ʌ', 'ɔ', 'æ', 'ɐ', 'ɶ', 'ɑ', 'ɒ']\n"
     ]
    }
   ],
   "source": [
    "print(textgrids.vowels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
